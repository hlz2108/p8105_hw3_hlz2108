---
title: "HW 2 for P8105 - hlz2108"
author: "Helen Zhang"
date: "September 30, 2020"
output: github_document
---

The code chunk below loads libraries.

```{r Library_Setup}
library(tidyverse)
library(readxl)
```

## Problem 1

Reading in Mr. Trash Wheel dataset.

```{r Trash_Wheel_df}
trash_wheel_df =
  read_excel(
    "./data/Trash_Wheel.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols ("A:N")) %>%
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  ) %>% 
view
```

Read precipitation data!

```{r Precipitation_df}
precip_2018 = 
 read_excel(
    "./data/Trash_Wheel.xlsx",
    sheet = "2018 Precipitation",
    skip = 1
 ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)
  
precip_2017 = 
 read_excel(
    "./data/Trash_Wheel.xlsx",
    sheet = "2017 Precipitation",
    skip = 1
 ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

Now combine annual precipitation. In the following code chunk, I create a "helper" tibble that contains pairs of numeric and character ways of representing month, and then merge that (using month number as a key) with the precipitation dataset. This technique is one I use often when I need to recode a moderate or large number of values for a variable. 


```{r Combine_Precip}
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df =
  bind_rows(precip_2018,precip_2017)

left_join(precip_df, month_df, by = "month")
```

This data set contains information from the Mr. Trashwheel trash collector in Baltimore, Maryland. As trash enters the inner harbor, the trashwheel collects that trash, and stores it in a dumpster. The dataset contains information on year, month, and trash collected, including some specific kinds of trash. There are a total of `r nrow(trash_wheel_df)` rows in our final dataset. Additional data sheets include month precipitation data. In this dataset:

* The median number of sports balls found in a dumpster in 2017 was `r trash_wheel_df %>% filter(year == 2017) %>% pull(sports_balls) %>% median()`
* The total precipitation in 2018 was `r precip_df %>% filter(year == 2018) %>% pull(total) %>% sum()` inches.

## Problem 2

Reading in and cleaning NYC Transit Data.

```{r NYC_Transit_df}
NYC_transit_df = 
  read_csv(
    "./data/NYC_Transit_Data.csv", col_types = cols(
      Route8 = col_character(),
      Route9 = col_character(),
      Route10 = col_character(),
      Route11 = col_character()
    )) %>%
  janitor::clean_names() %>%
  select(line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) %>% 
  mutate(entry = recode(entry,`YES` = TRUE, `NO` = FALSE )) %>% 
view
```

This data set contains information related to each entrance and exit for each subway station in NYC. In this first code chunk, I have kept only information on the station name, the line it is on, latitude and longitudinal coordinates, routes they serve, if entry is allowed and what type of entry it is, and whether the station is ADA compliant. To clean this dataset, I first reformatted the names using the janitor package. I then recoded the entry variable as a logical vector, so that entry was coded as either True or False instead of Yes or No. After cleaning the data, the dimensions of the data set are `r nrow(NYC_transit_df)` rows by `r ncol(NYC_transit_df)` columns.
This dataset is not tidy at the moment as there are still a number of NA values and routes are spread across 11 columns and not condensed into 1.

There are a total of `r count(distinct(NYC_transit_df, station_name, line))` distinct stations.

`r filter(NYC_transit_df, ada == "TRUE") %>% distinct(station_name, line) %>% nrow` stations are ADA compliant.

The proportion of station entrances/exits without vending that allow entrance are `r (filter(NYC_transit_df, vending == "NO" & entry == "TRUE") %>% nrow) / (filter(NYC_transit_df, vending == "NO") %>% nrow)`.

The code chunk below creates a dataset that tidies up the previous NYC Transit dataset, and reformats the data so that the route number and route name are distinct variables.

```{r Transit_Tidy_df}
transit_tidy_df =
  NYC_transit_df %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    values_to = "route_line") %>% 
  relocate("route_line") %>% 
  drop_na(route_line) %>% 
  view()
```

In our final dataset, there are a total of `r nrow(transit_tidy_df)` rows and `r ncol(transit_tidy_df)` columns. The data is tidy in the final dataset as route line has been condensed into 1 variable and the NA responses are no longer present.

The code chunk below creates a dataset that contains only stations that serve the A Train.

```{r ATrain_df}
ATrain_df = 
  filter(transit_tidy_df, route_line == "A")
```

There are `r count(distinct(ATrain_df, station_name, line))` distinct stations that serve the A train.

Of the stations that serve the A train, `r filter(ATrain_df, ada == TRUE) %>% distinct(station_name, line) %>% nrow` stations are ADA compliant.

## Problem 3

**Reading in FiveThirtyEight data**

Cleaning and tidying up pols_month dataset.

```{r pols_month_df}
pols_month_df = 
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>%
  janitor::clean_names() %>% 
  separate(mon, into = c("year", "month", "day")) %>% view

month_df = 
	tibble(
		month = c("01", "02", "03", "04", "05", "06", "07", "08", "09", "10", "11", "12"),
		month_name = month.abb
	)

pols_tidy_df = 
	left_join(pols_month_df, month_df, by = "month") %>% 
  relocate(month_name, prez_gop, prez_dem) %>% 
  mutate(prez_gop = na_if(prez_gop, 0), prez_dem = na_if(prez_dem, 0)) %>%
    pivot_longer(
    prez_gop:prez_dem,
    names_to = "president",
    values_to = "president_value") %>%
  mutate(president = recode(president, `prez_gop` = 'gop', `prez_dem` = 'dem')) %>% 
  drop_na(president_value) %>%
  arrange(year, month) %>% 
  select(-president_value, -month, -day) %>%
  rename(month = month_name) %>% 
  relocate(year, month) %>% 
  view()
```

Cleaning and tidying the snp.csv dataset.

```{r snp_df}
snp_df = 
  read_csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("month", "day", "year")) %>%
  view

month2_df = 
	tibble(
		month = c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12"),
		month_name = month.abb
	)

snp_tidy_df = 
	left_join(snp_df, month2_df, by = "month") %>%
  arrange(year, month) %>% 
  select(-month, -day) %>% 
  rename(month = month_name) %>%  
  relocate(year, month) %>% 
  view
```

Cleaning up and tidying unemployment dataset.

```{r unemployment_df}
unemployment_tidy_df =
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv", col_types = cols(
    Year = col_character()
    )) %>%
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemployment") %>%
  rename(year = Year) %>% 
  view
```


Merging datasets together!

```{r merging}
snp_pols_df = 
  left_join(pols_tidy_df, snp_tidy_df, by = c("year" = "year", "month" = "month")) %>% view

FiveThirtyEight_df = 
  left_join(snp_pols_df, unemployment_tidy_df, by = c("year" = "year", "month" = "month")) %>% view
```

The pols-month dataset contains information on the political landscape of the US, such as the number of national politicians who are democratic or republican at the presidential, governor, and senate level at a particular date. In cleaning this dataset, I cleaned the names using the _janitor_ package, and separated the date into three variables, year, month and day, keeping only year and month for dataset consistency. I then converted the month variable into their abbreviated month names. Lastly, I created a new _president_ variable that would reveal whether the president at a particular month and year was either a republican of democrat. I did this by combining the prez_gop and prez_dem variables into 1 variable. Lastly, I arranged the data by month and year as the leading columns so that I could merge it with my other datasets later on.

The snp dataset contains information on the closing vales of the S&P stock index on the associated month and year. The data wrangling process was similar to that in the pols-month dataset. After cleaning the variable names, I began with breaking the date variable into three separate ones: year, month and day, keeping only year and month. Month was then converted into its abbreviated month name and the data was arranged by year and month as the leading columns. 

The unemployment data set contains information on the unemployment percentage of a particular month in a year. For consistency, I transformed the months columns (Jan-Dec) into rows using _pivot_longer_, so that I would have a month and unemployment variable. I then arranged the dataset by year and month as the leading columns.

The final dataset, FiveThirtyEight_df, merges the previous 3 datasets together, by year and by month, creating a large dataset that contains information on the political landscape, stock performance, and unemployment percentages for a particular month and year. This final dataset dimensions are  `r nrow(FiveThirtyEight_df)` rows by `r ncol(FiveThirtyEight_df)` columns. The dataset contains information between the years `r min(pull(FiveThirtyEight_df, year))` and `r max(pull(FiveThirtyEight_df, year))`. One key variable in the FiveThirtyEight dataset is the **president** variable, which shows you whether the president at a certain month was either republican or democratic, as well as the unemployment percentage and closing value for the S&P stock index in that month, indicators of economic performance. This information could be useful for evaluating a president's performance.

One slight caveat to the **president** variable is that during August 1974 to December 1974, President Nixon resigned due to the Watergate scandal and there was no President in office as the Vice President Gerald Ford took over, but was not officially sworn in until December 1974. In the original dataset, prez_gop was labeled as 2, indicating that there was some unique situation at hand where the president was from the gop party but was not an _official_ president. Because of this and giving the historical events at the time, I opted to include those "2" values in the final dataset so that I could show information during August through December of 1974, despite there not being an _official_ president.