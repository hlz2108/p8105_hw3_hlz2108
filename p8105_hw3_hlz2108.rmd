---
title: "HW 3 for P8105 - hlz2108"
author: "Helen Zhang"
date: "October 5, 2020"
output: github_document
---
### Due date

Due: October 10 at 10:00pm. 

### Points

| Problem         | Points    |
|:--------------- |:--------- |
| Problem 0       | 20        |
| Problem 1       | --        |
| Problem 2       | 40        |
| Problem 3       | 40        |
| Optional survey | No points |
Below is the code for setup:

```{r setup}
library(tidyverse)
library(dplyr)
library(readxl)
library(ggplot2)
library(p8105.datasets)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 0

This “problem” focuses on structure of your submission, especially the use git and GitHub for reproducibility, R Projects to organize your work, R Markdown to write reproducible reports, relative paths to load data from local files, and reasonable naming structures for your files.

## Problem 1

```{r instacart_df}
data("instacart")
```

This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns.

Observations are the level of items in order by user. 

How many aisles, and which are most items ordered from?

```{r aisle_count}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

Let's make a plot!
This plot shows the number of items ordered in each aisle, limited to aisles with more than 10000 items ordered.

```{r instacart_plot}
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>% 
  ggplot(aes(x = aisle, y = n)) +
  geom_point() + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

Let's make a table!
This table shows the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits” and the number of times each item is ordered.

```{r instacart_table1}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(aisle, rank) %>% 
  knitr::kable()
```

Apples vs. Ice-Cream
Making a second table.
This table shows the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week.

```{r instacart_table2}
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarise(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  )
```

## Problem 2

```{r accel_df}
accel_df = 
  read_csv("./data/accel_data.csv", col_types = cols(
      week = col_integer(),
      day_id = col_integer()
      )) %>%
  janitor::clean_names() %>% 
  mutate(
    weekend = case_when(
      day == "Monday" ~ "weekday",
      day == "Tuesday" ~ "weekday",
      day == "Wednesday" ~ "weekday",
      day == "Thursday" ~ "weekday",
      day == "Friday" ~ "weekday",
      day == "Saturday" ~ "weekend",
      day == "Sunday" ~ "weekend"
)) %>% 
  relocate("weekend") %>%
  pivot_longer(
    activity_1:activity_1440, 
    names_to = "activity",
    values_to = "activity_count") %>% 
  separate(activity, into = c("activity", "activity_minute")) %>%
  select(-activity) %>%
  mutate(
    activity_minute = as.numeric(activity_minute),
    day = factor(day),
    day = fct_relevel(day, c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))
    ) %>% view
```

The accel data set contains `r nrow(accel_df)` rows and `r ncol(accel_df)` columns. The dataset contains 5 weeks of accelerometer data collected from a 63 year-old male with BMI 25, who was admitted to the Advanced Cardiac Care Center of Columbia University Medical Center and diagnosed with congestive heart failure (CHF). The variables in this dataset are `r names(accel_df)`. Below is a detailed description of several variables of interest:

* _day_id_ is a `r class(pull(accel_df,day_id))` variable and indicates the day the accelerometer data was collected.

* _day_ is a `r class(pull(accel_df,day))` variable that was created in order to make the original `day_id` variable easier to understand.

* _week_ is a `r class(pull(accel_df, week))` variable and indicates the week the accelerometer data was collected.

* _weekend_ is a `r class(pull(accel_df, weekend))` variable that indicates whether the information was collected on a weekend vs. a weekday.

* _activity_minute_ is a `r class(pull(accel_df, activity_minute))` variable that indicates the minute when the activity count was collected, corresponding to each minute of a 24-hour day starting at midnight.

```{r aggregate_accel}
accel_df %>% 
  group_by(day_id, day) %>%
  summarize(total_activity = sum(activity_count)) %>% 
  knitr::kable()
```

Activity counts were at their lowest on the two Saturdays prior to end of data collection (weeks 4 and 5). The individual appears to be most active on the days leading up to and after the weekend, and during the weekend (Friday-Monday).

```{r accel_plot}
accel_df %>% 
  ggplot(aes(x = activity_minute, y = activity_count, color = day)) + 
  geom_line() +
  labs(
    title = "24-Hour Activity Count by Day",
    x = "Time",
    y = "Activity Count",
    caption = "Data from the accel dataset"
  ) + 
  scale_x_continuous(
    breaks = c(0, 360, 720, 1080, 1440), 
    labels = c("12AM", "6AM", "12PM", "6PM", "11:59PM"),
    limits = c(0, 1440)
    )
```

Activity is lowest during sleeping hours, the individual appears to be more active on 
the weekends, in the evening hours around 8-10pm.

## Problem 3

Loading dataset.
```{r ny_noaa_df}
data("ny_noaa")
```

The NY_NOAA dataset contains information taken from the NOAA National Climatic Data Center. It contains information from all New York state weather stations from January 1, 1981 through December 31, 2010.
The NOAA dataset contains `r nrow(ny_noaa)` rows and `r ncol(ny_noaa)` columns.

The variables in the data set are:

* `id`: Weather station ID
* `date`: Date of observation
* `prcp`: Precipitation (tenths of mm)
* `snow`: Snowfall (mm)
* `snwd`: Snow depth (mm)
* `tmax`: Maximum temperature (tenths of degrees C)
* `tmin`: Minimum temperature (tenths of degrees C)

Because not all weather stations in NY collect all these variables, the original dataset contains extensive amount of missing data.

```{r noaa_tidy}
noaa_tidy = ny_noaa %>% 
  separate(date, into = c("year", "month", "day")) %>%
  mutate(
    prcp = prcp / 10 ,
    tmax = as.numeric(tmax) / 10,
    tmin = as.numeric(tmin) / 10,
    year = as.numeric(year),
    day = as.numeric(day),
    month = recode_factor(month,
          "01" = "January",
          "02" = "February",
          "03" = "March",
          "04" = "April",
          "05" = "May",
          "06" = "June",
          "07" = "July",
          "08" = "August",
          "09" = "September",
          "10" = "October",
          "11" = "November",
          "12" = "December"
    )) %>% 
  relocate(year, month, day, everything())
```

Several variables were converted into standard units. `prcp`, which was measured in tenths of mm, was converted into mm and `tmax` and `tmin`, which were measured in tenths of degrees C, was converted into degrees C.

```{r snowfall_noaa}
noaa_tidy %>% 
  count(snow) %>%
  arrange(desc(n))
```

From the dataframe above, you can see that the most commonly observed value for snowfall was 0, indicating that on most days in NYS, it is not snowing. This makes sense as snow is most likely to occur during the winter season (~3 months or so), and not year round.

```{r plot_noaa_tmax}
tmax_noaa = noaa_tidy %>% 
  filter(month %in% c("January", "July")) %>% 
  group_by(id, year, month) %>% 
  summarize(mean_tmax = mean(tmax, na.rm = TRUE))

ggplot(tmax_noaa, aes(x = year, y = mean_tmax, group = id, color = id)) +
  geom_line() +
  labs(
    title = "Avg Max Temp in January and July in each NY Station Across Years",
    x = "Year",
    y = "Temp (°C)",
    caption = "Data from the NOAA dataset"
  ) +
  scale_x_continuous(
    breaks = c(1980, 1985, 1990, 1995, 2000, 2005, 2010)
    ) +
  facet_grid(. ~ month) +
  theme(
    legend.position = "none")

```

Is there any observable / interpretable structure? Any outliers?

```{r}

```

Make a two-panel plot showing (i) tmax vs tmin for the full dataset (note that a scatterplot may not be the best option); and (ii) make a plot showing the distribution of snowfall values greater than 0 and less than 100 separately by year.

